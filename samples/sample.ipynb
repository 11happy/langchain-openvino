{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1157a78-f814-4aa2-ae18-b2849d773bb5",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00fdd9a1-6f9b-4471-8ce8-35b65ec65dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/11happy/langchain-openvino.git@v0.1.1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/11happy/langchain-openvino.git 'C:\\Users\\Happy\\AppData\\Local\\Temp\\pip-req-build-0boimd__'\n",
      "  Running command git checkout -q 84b02032d9a7e2a3abbc8394179d96aaf928c6a8\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/11happy/langchain-openvino.git (to revision v0.1.1) to c:\\users\\happy\\appdata\\local\\temp\\pip-req-build-0boimd__\n",
      "  Resolved https://github.com/11happy/langchain-openvino.git to commit 84b02032d9a7e2a3abbc8394179d96aaf928c6a8\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.60 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openvino==0.1.0) (0.3.68)\n",
      "Requirement already satisfied: openvino<2026.0.0,>=2025.1.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openvino==0.1.0) (2025.2.0)\n",
      "Requirement already satisfied: openvino-genai<2026.0.0.0,>=2025.1.0.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openvino==0.1.0) (2025.2.0.0)\n",
      "Requirement already satisfied: openvino-tokenizers<2026.0.0.0,>=2025.1.0.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openvino-tokenizers[transformers]<2026.0.0.0,>=2025.1.0.0->langchain-openvino==0.1.0) (2025.2.0.1)\n",
      "Requirement already satisfied: optimum-intel<2.0.0,>=1.23.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openvino==0.1.0) (1.24.0)\n",
      "Requirement already satisfied: pdoc<16.0.0,>=15.0.4 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openvino==0.1.0) (15.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.11.4 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openvino==0.1.0) (2.11.7)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (4.14.1)\n",
      "Requirement already satisfied: numpy<2.3.0,>=1.16.6 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openvino<2026.0.0,>=2025.1.0->langchain-openvino==0.1.0) (2.2.6)\n",
      "Requirement already satisfied: openvino-telemetry>=2023.2.1 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openvino<2026.0.0,>=2025.1.0->langchain-openvino==0.1.0) (2025.1.0)\n",
      "Requirement already satisfied: transformers<=4.51.3,>=4.36.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]<=4.51.3,>=4.36.0; extra == \"transformers\"->openvino-tokenizers[transformers]<2026.0.0.0,>=2025.1.0.0->langchain-openvino==0.1.0) (4.51.3)\n",
      "Requirement already satisfied: tiktoken<=0.9.0,>=0.3.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openvino-tokenizers[transformers]<2026.0.0.0,>=2025.1.0.0->langchain-openvino==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (2.7.1)\n",
      "Requirement already satisfied: optimum==1.26.* in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (1.26.1)\n",
      "Requirement already satisfied: datasets>=1.4.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (3.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (80.9.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (1.15.3)\n",
      "Requirement already satisfied: onnx in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (1.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optimum==1.26.*->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (0.33.2)\n",
      "Requirement already satisfied: Jinja2>=2.11.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdoc<16.0.0,>=15.0.4->langchain-openvino==0.1.0) (3.1.6)\n",
      "Requirement already satisfied: pygments>=2.12.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdoc<16.0.0,>=15.0.4->langchain-openvino==0.1.0) (2.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=1.1.1 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdoc<16.0.0,>=15.0.4->langchain-openvino==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.11.4->langchain-openvino==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.11.4->langchain-openvino==0.1.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.11.4->langchain-openvino==0.1.0) (0.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (2025.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (0.23.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken<=0.9.0,>=0.3.0->openvino-tokenizers[transformers]<2026.0.0.0,>=2025.1.0.0->langchain-openvino==0.1.0) (2024.11.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<=4.51.3,>=4.36.0->transformers[sentencepiece]<=4.51.3,>=4.36.0; extra == \"transformers\"->openvino-tokenizers[transformers]<2026.0.0.0,>=2025.1.0.0->langchain-openvino==0.1.0) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<=4.51.3,>=4.36.0->transformers[sentencepiece]<=4.51.3,>=4.36.0; extra == \"transformers\"->openvino-tokenizers[transformers]<2026.0.0.0,>=2025.1.0.0->langchain-openvino==0.1.0) (0.5.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]<=4.51.3,>=4.36.0; extra == \"transformers\"->openvino-tokenizers[transformers]<2026.0.0.0,>=2025.1.0.0->langchain-openvino==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers[sentencepiece]<=4.51.3,>=4.36.0; extra == \"transformers\"->openvino-tokenizers[transformers]<2026.0.0.0,>=2025.1.0.0->langchain-openvino==0.1.0) (6.31.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (3.12.13)\n",
      "Requirement already satisfied: anyio in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.66.3->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.4.0->optimum-intel<2.0.0,>=1.23.0->langchain-openvino==0.1.0) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\happy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.60->langchain-openvino==0.1.0) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/11happy/langchain-openvino.git@v0.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28974ff6-38c2-4216-9e1f-0343c7703a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openvino.chat_model import ChatOpenVINO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fedb599-f3e4-4d47-b8c1-b080ade80be8",
   "metadata": {},
   "source": [
    "## Loading an OpenVINO model and running simple inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e35016f-31c8-48fc-8dbc-64c4dd6d8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"D:\\main-model\"  # Change path accordingly\n",
    "\n",
    "chat_model = ChatOpenVINO(\n",
    "    model_path=model_path,\n",
    "    device=\"CPU\",\n",
    "    max_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_k=20,\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d4f8b4-af20-468c-b60b-c4bd1f1c2427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: OpenVINO is an open-source project initiated by Intel to accelerate deep learning and computer vision applications. It provides tools and frameworks that enable developers to deploy AI models on Intel hardware, especially Intel Neural Networks Accelerator (NNPI) technology, which includes Intel Movidius Vision Accelerator (VDA) and Intel Movidius Myriad X Gen 2. The OpenVINO toolkit offers a Model Optimizer for converting trained models into an optimized format for inference, an Inference Engine for executing the models, and other tools for managing and deploying AI\n"
     ]
    }
   ],
   "source": [
    "response = chat_model.invoke(\"What is OpenVINO\")\n",
    "print(\"Response:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92368060-d562-492a-ae0b-c298e258af27",
   "metadata": {},
   "source": [
    "## Changing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae0cf3a4-e81e-40f2-9228-34d9d66c17d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: A neural network, in the context of computer science and machine learning, refers to a series of algorithms and data structures designed to recognize patterns in data. It consists of layers of interconnected nodes or neurons, each performing simple calculations. The main goal of a neural network is to simulate the behavior of biological neural networks, like those that make up the human brain.\n",
      "\n",
      "These networks are primarily used in machine learning and artificial intelligence, and they can be trained to identify complex patterns, making\n"
     ]
    }
   ],
   "source": [
    "chat_model = (\n",
    "    chat_model.with_temperature(0.9)\n",
    "    .with_top_k(40)\n",
    "    .with_top_p(0.95)\n",
    "    .with_max_tokens(100)\n",
    "    .with_do_sample(True)\n",
    "    .with_device(\"CPU\")\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(\"What is a neural network ?\")\n",
    "print(\"Response:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905eb81-5de3-4358-a5de-2eddcdfaa02c",
   "metadata": {},
   "source": [
    "## Streaming text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1822c0-38dd-47bd-967a-f36630b52544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once, a farmer discovered a small, shimmering seed buried in his field. Skeptical, he planted it. The seed sprouted into a tree with iridescent leaves that sang in the wind. People came from afar, marveling at the lush foliage. The tree's fruit bore the most succulent fruits the world had ever tasted. The farmer'ranthropic community grew around the tree, celebrating its wonder and prosperity. Legends say the tree gave life and healing to all who approached it. It stood as a testament to the magic that can arise from an unexpected place."
     ]
    }
   ],
   "source": [
    "for chunk in chat_model.with_max_tokens(512).stream(\"Tell me a story within 100 words\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43f712-63fa-4e4e-b238-2d02e394a6ed",
   "metadata": {},
   "source": [
    "## Speculative decoding with draft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbd0894-1b03-49cc-b5f6-8ddb23a38ed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to generate response: Check 'content_length <= prompt_ids.size() + m_generated_ids.size()' failed at C:\\Jenkins\\workspace\\private-ci\\ie\\build-windows-vs2022\\b\\repos\\openvino.genai\\src\\cpp\\src\\sequence_group.cpp:31\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_openvino\\chat_model.py:283\u001b[0m, in \u001b[0;36mChatOpenVINO._generate\u001b[1;34m(self, messages, run_manager, stop, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Check 'content_length <= prompt_ids.size() + m_generated_ids.size()' failed at C:\\Jenkins\\workspace\\private-ci\\ie\\build-windows-vs2022\\b\\repos\\openvino.genai\\src\\cpp\\src\\sequence_group.cpp:31\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m draft_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdraft-model\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change it accordingly\u001b[39;00m\n\u001b[0;32m      3\u001b[0m speculative_decoding_chat_model \u001b[38;5;241m=\u001b[39m ChatOpenVINO(\n\u001b[0;32m      4\u001b[0m     model_path\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[0;32m      5\u001b[0m     draft_model_path\u001b[38;5;241m=\u001b[39mdraft_model_path,\n\u001b[0;32m      6\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mspeculative_decoding_chat_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplain what is deep learning in reference to artificial intelligence?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m speculative_decoding_chat_model\u001b[38;5;241m.\u001b[39mwith_max_tokens(\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplain what is deep learning in reference to artificial intelligence?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    375\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    379\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    380\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    381\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    382\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    383\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    384\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    385\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    386\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    387\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    388\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    961\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    962\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 782\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    783\u001b[0m                 m,\n\u001b[0;32m    784\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    785\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    786\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    787\u001b[0m             )\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1029\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1030\u001b[0m     )\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_openvino\\chat_model.py:288\u001b[0m, in \u001b[0;36mChatOpenVINO._generate\u001b[1;34m(self, messages, run_manager, stop, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    284\u001b[0m         msg,\n\u001b[0;32m    285\u001b[0m         configuration,\n\u001b[0;32m    286\u001b[0m     )\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to generate response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m gen \u001b[38;5;241m=\u001b[39m ChatGeneration(message\u001b[38;5;241m=\u001b[39mAIMessage(content\u001b[38;5;241m=\u001b[39mresp))\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[gen])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to generate response: Check 'content_length <= prompt_ids.size() + m_generated_ids.size()' failed at C:\\Jenkins\\workspace\\private-ci\\ie\\build-windows-vs2022\\b\\repos\\openvino.genai\\src\\cpp\\src\\sequence_group.cpp:31\n"
     ]
    }
   ],
   "source": [
    "draft_model_path = r\"D:\\draft-model\"  # Change it accordingly\n",
    "\n",
    "speculative_decoding_chat_model = ChatOpenVINO(\n",
    "    model_path=model_path,\n",
    "    draft_model_path=draft_model_path,\n",
    "    max_tokens=64,\n",
    ")\n",
    "response = speculative_decoding_chat_model.invoke(\n",
    "    \"explain what is deep learning in reference to artificial intelligence?\"\n",
    ")\n",
    "print(\"Response:\", response.content)\n",
    "\n",
    "for chunk in speculative_decoding_chat_model.with_max_tokens(32).stream(\n",
    "    \"explain what is deep learning in reference to artificial intelligence?\"\n",
    "):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925e9ef-2a7e-4009-8382-ad74aa7ee716",
   "metadata": {},
   "source": [
    "## Prompt Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa68b055-9c9c-4b58-9998-d40b81a7f4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: OpenVINO is an open-source project created by Intel and The University of Illinois Urbana-Champaign that focuses on developing tools for optimizing machine learning models for on-device deployment. Initially, OpenVINO was created as an effort by Intel to improve its own deployment capabilities but eventually turned into a widely utilized toolkit.\n",
      "\n",
      "It provides a variety of applications, including its Inference Engine, which is an open-source inference engine that allows developers to optimize and deploy pre-trained neural networks to specialized hardware like Intel CPUs or GPUs.\n",
      "ran for on-device inference, particularly beneficial for applications requiring real-time processing, such as autonomous vehicles, drones, and smartphones.\n",
      "\n",
      "OpenVINO offers a set of command-line tools, Python APIs, and model quantization methods, enabling efficient acceleration of AI workloads on Intel hardware. Its aim is to make it easier and quicker for AI developers to implement AI solutions across a wide range of platforms and devices.\n"
     ]
    }
   ],
   "source": [
    "prompt_lookup_model = ChatOpenVINO(\n",
    "    model_path=model_path,\n",
    "    prompt_lookup=True,\n",
    ")\n",
    "response = prompt_lookup_model.invoke(\"What is OpenVINO\")\n",
    "print(\"Response:\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0136c9-c998-473a-81d0-cd85c4f28f99",
   "metadata": {},
   "source": [
    "## LoRA Adapters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b1ed5-9f0e-4aea-958a-00b5682c3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_adapter_model = ChatOpenVino(\n",
    "    model_path=model_path, adapter_path=\"path/to/lora/adapters\"\n",
    ")\n",
    "response = prompt_lookup_model.invoke(\"What is OpenVINO\")\n",
    "print(\"Response:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d9421-6336-4504-aeb4-042e8f9e41f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
